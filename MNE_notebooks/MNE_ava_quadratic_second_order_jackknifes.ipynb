{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = np.load('/Users/iuliarusu/Documents/Sharpee/ProcAiryData/inpfull_op50_SF.npz')\n",
    "Y_full = np.load('/Users/iuliarusu/Documents/Sharpee/ProcAiryData/Yfull_op50_SF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_concat = np.concatenate([stimulus['arr_0'], stimulus['arr_1'], stimulus['arr_2'], stimulus['arr_3'], stimulus['arr_4'], stimulus['arr_5'], stimulus['arr_6']], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_concat = stimulus_concat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import AVA data from all cells\n",
    "AVA_0_df = pd.read_csv ('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_0_df.csv')\n",
    "AVA_1_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_1_df.csv') \n",
    "AVA_2_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_2_df.csv')\n",
    "AVA_3_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_3_df.csv') \n",
    "AVA_4_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_4_df.csv') \n",
    "AVA_5_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_5_df.csv') \n",
    "AVA_6_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_6_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_0 = np.array(AVA_0_df.iloc[:, 1: -2])\n",
    "AVA_1 = np.array(AVA_1_df.iloc[:, 1: -3])\n",
    "AVA_2 = np.array(AVA_2_df.iloc[:, 1: -3])\n",
    "AVA_3 = np.array(AVA_3_df.iloc[:, 1: -3])\n",
    "AVA_4 = np.array(AVA_4_df.iloc[:, 1: -3])\n",
    "AVA_5 = np.array(AVA_5_df.iloc[:, 1: -3])\n",
    "AVA_6 = np.array(AVA_6_df.iloc[:, 1: -3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_all = np.concatenate([AVA_0, AVA_1, AVA_2, AVA_3, AVA_4, AVA_5, AVA_6], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate stim 1 and stim 0, \n",
    "AVA_stim_0 = np.concatenate([AVA_0, AVA_1, AVA_6], axis = 0)\n",
    "AVA_stim_1 = np.concatenate([AVA_2, AVA_3, AVA_4, AVA_5], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins=10, nsamples=10):\n",
    "    response_vector = []\n",
    "    stimulus_vector = []\n",
    "    for _ in range(nsamples):\n",
    "        r = response[cell_idx, start_idx: start_idx + bin_size]\n",
    "        response_vector.append(np.average(r))\n",
    "        print('response', response_vector)\n",
    "\n",
    "        bin_stimuli = []\n",
    "        for i in range(num_bins):\n",
    "           \n",
    "            end_idx = (start_idx ) - (i * bin_size)\n",
    "            print('start_idx', start_idx)\n",
    "            print('end', end_idx)\n",
    "            start_idx_bin = end_idx + bin_size\n",
    "            print('start_idx_bin', start_idx_bin)\n",
    "\n",
    "            # Check if the calculated index is within the bounds\n",
    "            if start_idx_bin < 0:\n",
    "                break\n",
    "\n",
    "            # Append the average of stimulus over the bin\n",
    "            bin_stimuli.append(np.average(stimulus[0, end_idx:start_idx_bin]))\n",
    "            print('stim', stimulus[0, start_idx_bin:end_idx])\n",
    "            print('bin_stimuli', bin_stimuli)\n",
    "\n",
    "        # Collect all averages per sample\n",
    "        stimulus_vector.append(bin_stimuli)\n",
    "        print('stimulus_vector', stimulus_vector)\n",
    "\n",
    "        # Update start index for the next sample\n",
    "        start_idx += bin_size\n",
    "\n",
    "    # Convert list of lists into a 2D NumPy array\n",
    "    stimulus_matrix = np.array(stimulus_vector)  # Transpose to match expected dimensions\n",
    "\n",
    "    return stimulus_matrix, np.array(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_0 = stimulus_concat[0, :].reshape(1600, 1)\n",
    "stim_1 = stimulus_concat[2, :].reshape(1600, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_stim0 = []\n",
    "all_labels_stim0 = []\n",
    "\n",
    "bin_size = 10\n",
    "start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "num_bins = 10\n",
    "nsamples = 100 #amount of times you're moving over the data\n",
    "\n",
    "stimulus = stim_0.T\n",
    "response = AVA_stim_0\n",
    "cell_idx = 0 #cell in response\n",
    "# Calculate data and labels for each cell or half the cells\n",
    "num_cells = response.shape[0]  # or response.shape[0] // 2 for half of the cells\n",
    "for cell_idx in range(num_cells):\n",
    "    data, label = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)\n",
    "    all_data_stim0.append(data)\n",
    "    all_labels_stim0.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data__stim0_array = np.concatenate(all_data_stim0, axis=0)\n",
    "\n",
    "# Convert list of 1D arrays to a single 2D array (if all_labels consists of 1D arrays)\n",
    "all_labels__stim0_array = np.concatenate(all_labels_stim0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_stim1 = []\n",
    "all_labels_stim1 = []\n",
    "\n",
    "bin_size = 10\n",
    "start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "num_bins = 10\n",
    "nsamples = 100 #amount of times you're moving over the data\n",
    "\n",
    "stimulus = stim_1.T\n",
    "response = AVA_stim_1\n",
    "cell_idx = 0 #cell in response\n",
    "# Calculate data and labels for each cell or half the cells\n",
    "num_cells = response.shape[0]  # or response.shape[0] // 2 for half of the cells\n",
    "for cell_idx in range(num_cells):\n",
    "    data, label = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)\n",
    "    all_data_stim1.append(data)\n",
    "    all_labels_stim1.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data__stim1_array = np.concatenate(all_data_stim1, axis=0)\n",
    "\n",
    "# Convert list of 1D arrays to a single 2D array (if all_labels consists of 1D arrays)\n",
    "all_labels__stim1_array = np.concatenate(all_labels_stim1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate both stimuli\n",
    "all_data_array = np.concatenate([all_data__stim0_array, all_data__stim1_array], axis = 0)\n",
    "all_labels_array = np.concatenate([all_labels__stim0_array, all_labels__stim1_array], axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, Y = all_data_array, all_labels_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_quad_model(D, optimizer):\n",
    "\n",
    "    input_layer = keras.layers.Input((D,))\n",
    "\n",
    "    linear_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "    quadratic_layer = keras.layers.Dense(D,use_bias=False)(input_layer)\n",
    "\n",
    "    multiply_layer = keras.layers.Multiply()([quadratic_layer,input_layer])\n",
    "\n",
    "    ones_layer = keras.layers.Dense(1,use_bias=False,trainable=False,kernel_initializer='ones')(multiply_layer)\n",
    "\n",
    "    add_layer = keras.layers.Add()([linear_layer,ones_layer])\n",
    "\n",
    "    output_layer = keras.layers.Activation('sigmoid')(add_layer)\n",
    "\n",
    "    model = keras.models.Model(input_layer,output_layer)\n",
    "\n",
    "    model.compile(optimizer= optimizer, loss='binary_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_jackknife_models(S, Y):\n",
    "\n",
    "    patience = 3 # early stopping\n",
    "    epochs = 1000 # max number of cycles to train\n",
    "    all_best_weights = []\n",
    "\n",
    "    sq1, sq2, sq3, sq4 = np.array_split(S, 4)\n",
    "    yq1, yq2, yq3, yq4 = np.array_split(Y, 4)\n",
    "\n",
    "    j1 = {\n",
    "    'S_train': np.concatenate((sq2, sq3, sq4), axis=0),\n",
    "    'S_valid': sq1,\n",
    "    'Y_train': np.concatenate((yq2, yq3, yq4), axis=0),\n",
    "    'Y_valid': yq1\n",
    "}\n",
    "    j2 = {\n",
    "    'S_train': np.concatenate((sq1, sq3, sq4), axis=0),\n",
    "    'S_valid': sq2,\n",
    "    'Y_train': np.concatenate((yq1, yq3, yq4), axis=0),\n",
    "    'Y_valid': yq2\n",
    "}\n",
    "    j3 = {\n",
    "    'S_train': np.concatenate((sq1, sq2, sq4), axis=0),\n",
    "    'S_valid': sq3,\n",
    "    'Y_train': np.concatenate((yq1, yq2, yq4), axis=0),\n",
    "    'Y_valid': yq3\n",
    "}\n",
    "    j4 = {\n",
    "    'S_train': np.concatenate((sq1, sq2, sq3), axis=0),\n",
    "    'S_valid': sq4,\n",
    "    'Y_train': np.concatenate((yq1, yq2, yq3), axis=0),\n",
    "    'Y_valid': yq4\n",
    "}\n",
    "\n",
    "    jackknives = [j1, j2, j3, j4]\n",
    "\n",
    "    for i, jackknife in enumerate(jackknives):\n",
    "        S_train = jackknife['S_train']\n",
    "        S_valid = jackknife['S_valid']\n",
    "        Y_train = jackknife['Y_train']\n",
    "        Y_valid = jackknife['Y_valid']\n",
    "\n",
    " \n",
    "        adam_optimizer = Adam(learning_rate=0.001)\n",
    "        best_weights = []\n",
    "        \n",
    "    # Creating the model with the optimizer passed as an argument\n",
    "        model = make_quad_model(S_train.shape[1], adam_optimizer)\n",
    "\n",
    "    # Setting up callbacks\n",
    "        filepath = f'best_weights_{i}.weights.h5' \n",
    "        callbacks = [\n",
    "                EarlyStopping(patience=patience, min_delta=1e-5, monitor='val_loss', verbose=1),\n",
    "                ModelCheckpoint(filepath=filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        ]\n",
    "\n",
    "    # Training the model\n",
    "        H = model.fit(S_train, Y_train, epochs=epochs, callbacks=callbacks, validation_data=(S_valid, Y_valid), verbose=2)\n",
    "        print(model.summary())\n",
    "        model.load_weights(filepath)#loads the best weights from the training\n",
    "        best_weights.append(model.get_weights()) #retreives best weights from load_weights callback\n",
    "    \n",
    "        all_best_weights.append(best_weights)\n",
    "\n",
    "    return all_best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(S, Y, num_models=4, global_seed = 24):\n",
    "    np.random.seed(global_seed)\n",
    "    test_size = 0.25\n",
    "    patience = 3\n",
    "    epochs = 1000\n",
    "    all_best_weights = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(num_models):\n",
    "        seed = np.random.randint(0, 1000)  # Random seed for each iteration\n",
    "        adam_optimizer = Adam(learning_rate=0.001)\n",
    "        best_weights = []\n",
    "        # Splitting the dataset\n",
    "        S_train, S_valid, Y_train, Y_valid = train_test_split(S, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Creating the model with the optimizer passed as an argument\n",
    "        model = make_quad_model(S_train.shape[1], adam_optimizer)\n",
    "\n",
    "    # Setting up callbacks\n",
    "        filepath = f'best_quad_AVA_weights_{i}.weights.h5' \n",
    "        callbacks = [\n",
    "                EarlyStopping(patience=patience, min_delta=1e-5, monitor='val_loss', verbose=1),\n",
    "                ModelCheckpoint(filepath=filepath, save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        ]\n",
    "\n",
    "    # Training the model\n",
    "        H = model.fit(S_train, Y_train, epochs=epochs, callbacks=callbacks, validation_data=(S_valid, Y_valid), verbose=2)\n",
    "        print(model.summary())\n",
    "        model.load_weights(filepath)#loads the best weights from the training\n",
    "        best_weights.append(model.get_weights()) #retreives best weights from load_weights callback\n",
    "    \n",
    "        all_best_weights.append(best_weights)\n",
    "\n",
    "    return all_best_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_weights = run_jackknife_models(S, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best_weights[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symmetrized_0 = (np.array(all_best_weights[0][0][0]) + np.array(all_best_weights[0][0][0]).transpose()) / 2\n",
    "symmetrized_1 = (np.array(all_best_weights[1][0][0]) + np.array(all_best_weights[1][0][0]).transpose()) / 2\n",
    "symmetrized_2 = (np.array(all_best_weights[2][0][0]) + np.array(all_best_weights[2][0][0]).transpose()) / 2\n",
    "symmetrized_3 = (np.array(all_best_weights[3][0][0]) + np.array(all_best_weights[3][0][0]).transpose()) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.matrix.flatten(symmetrized_0)\n",
    "f1 = np.matrix.flatten(symmetrized_1)\n",
    "f2 = np.matrix.flatten(symmetrized_2)\n",
    "f3 = np.matrix.flatten(symmetrized_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.outer(f0, f0.T) + np.outer(f3, f3.T)  + np.outer(f1, f1.T) + np.outer(f2, f2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sym = (A + A.T)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eigen = np.linalg.eigh(A_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = A_eigen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(np.real(eigenvalues)),  marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(A_eigen[1][: , -1], f0)\n",
    "\n",
    "#these are negative, need to flip the sign of the eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect = A_eigen[1][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect_0 = np.reshape(eigenvect, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect_0_sym = (eigenvect_0 + eigenvect_0.T)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigen_decomp = np.linalg.eig(eigenvect_0_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigen_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(top_eigen_decomp[1][:, 3])\n",
    "plt.title('Top Eigenvector AVA Motor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(top_eigen_decomp[1][:, 3])\n",
    "plt.title('Top Eigenvector AVA Motor')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Quad Component's Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate variance of weights \n",
    "def calculate_dots(J,s):\n",
    "    dots = []\n",
    "    for i in range(s.shape[0]):\n",
    "        dot1 = np.dot(J, s[i])\n",
    "        dot2 = np.dot(J, s[i].T)\n",
    "        dots.append(dot2)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = symmetrized_0 + symmetrized_1 + symmetrized_2 + symmetrized_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = calculate_dots(J = J, s= S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(var)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(var)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetrized_eigen_0 = np.linalg.eig(symmetrized_0)\n",
    "symmetrized_eigen_1 = np.linalg.eig(symmetrized_1)\n",
    "symmetrized_eigen_2 = np.linalg.eig(symmetrized_2)\n",
    "symmetrized_eigen_3 = np.linalg.eig(symmetrized_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetrized_eigen_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(symmetrized_eigen_3[1][:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackknife_0_eigen_0 = np.reshape(symmetrized_eigen_0[1][:, 2], (-1, 1))\n",
    "jackknife_1_eigen_0 = np.reshape(symmetrized_eigen_1[1][:, 1], (-1, 1))\n",
    "jackknife_2_eigen_0 = np.reshape(symmetrized_eigen_2[1][:, 3], (-1, 1))\n",
    "jackknife_3_eigen_0 = np.reshape(symmetrized_eigen_3[1][:, 1], (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_weights = np.concatenate([\n",
    "    jackknife_0_eigen_0,\n",
    "    jackknife_1_eigen_0,\n",
    "    jackknife_2_eigen_0,\n",
    "    jackknife_3_eigen_0\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ava = np.average(ava_weights, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_weights_df = pd.DataFrame(ava_weights)\n",
    "ava_weights_df.columns = ['Jackknife 1', 'Jackknife 2', 'Jackknife 3', 'Jackknife 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_weights_df['Average'] = mean_ava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_x = ava_weights_df.index.max() - ava_weights_df.index\n",
    "\n",
    "# Plotting each column in the DataFrame\n",
    "for column in ava_weights_df.columns:\n",
    "    plt.plot(reversed_x, ava_weights_df[column], label=column)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Weights Across Different Models: AVA Sensory Receptive Field')\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Weights Value')\n",
    "\n",
    "plt.xticks(reversed_x, labels=ava_weights_df.index)  # Set custom ticks and labels\n",
    "\n",
    "# Reverse the x-axis so that 0 starts at the origin and increases to the left\n",
    "\n",
    "\n",
    "# Show the legend and plot\n",
    "plt.legend(title='Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = ava_weights_df[['Jackknife 1', 'Jackknife 2', 'Jackknife 3', 'Jackknife 4']].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = std_dev / np.sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(x=reversed_x, y=mean_ON, yerr=sem, fmt='-o', label='Average with SEM', ecolor='red', capsize=5, linestyle='-', marker='o', color='blue')\n",
    "plt.title('ON Receptive Field ')\n",
    "plt.xlabel('Time')\n",
    "ticks = ON_weights_df.index\n",
    "plt.xticks(ticks, labels=ticks[::-1]) \n",
    "plt.ylabel('Stimulus')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average over jackknives by averaging full matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_matrix = (symmetrized_0 + symmetrized_1 + symmetrized_2 + symmetrized_3)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method doesn't yeild any compex numbers after the eigendecomposition\n",
    "avg_matrix_decomp = np.linalg.eig(avg_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvals = np.sort(avg_matrix_decomp[0])\n",
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eigenvals,  marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average over jackknives with flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = np.matrix.flatten(symmetrized_0)\n",
    "f1 = np.matrix.flatten(symmetrized_1)\n",
    "f2 = np.matrix.flatten(symmetrized_2)\n",
    "f3 = np.matrix.flatten(symmetrized_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.iscomplex(f0).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_outer =  np.outer(f0, f0.T)\n",
    "print(np.iscomplex(f0_outer).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.outer(f0, f0.T) + np.outer(f1, f1.T) + np.outer(f2, f2.T) + np.outer(f3, f3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.iscomplex(A).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sym = (A + A.T)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eigen = np.linalg.eigh(A_sym)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = A_eigen[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(eigenvalues),  marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top most eigenvalue's eigenvector\n",
    "eigenvect = A_eigen[1][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect_0 = np.reshape(eigenvect, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect_0_sym = (eigenvect_0 + eigenvect_0.T)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect_0_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigen_decomp = np.linalg.eig(eigenvect_0_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_eigen_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(top_eigen_decomp[1][:, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvect_0_diag = np.linalg.eig(eigenvect_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_eigenval = np.real(eigenvect_0_diag[0])\n",
    "real_eigenvect = np.real(eigenvect_0_diag[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_eigenval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_eigenvect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_eigenvect[0],  marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dots(w,s):\n",
    "    dots = []\n",
    "    for i in range(s.shape[0]):\n",
    "        dot = np.dot(w, s[i])\n",
    "        dots.append(dot)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = calculate_dots(w = real_eigenvect[0], s= S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(var)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetrized_eigen_0 = np.linalg.eig(symmetrized_0)\n",
    "symmetrized_eigen_1 = np.linalg.eig(symmetrized_1)\n",
    "symmetrized_eigen_2 = np.linalg.eig(symmetrized_2)\n",
    "symmetrized_eigen_3 = np.linalg.eig(symmetrized_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetrized_eigen_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average all symmertized matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten each symmetrized matrix, do its outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional, plot the eigenvalues\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.sort(symmetrized_eigen_0[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eigenvectors and eigenvalues from original\n",
    "#eigenvalues_0, eigenvectors_0 = np.linalg.eig(all_best_weights[0][0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract eigenvalues from weights from weights matrix\n",
    "test_eigen_0 = np.linalg.eig(np.matmul(np.array(all_best_weights[0][0][0]), np.array(all_best_weights[0][0][0]).transpose()))\n",
    "test_eigen_1 = np.linalg.eig(np.matmul(np.array(all_best_weights[1][0][0]), np.array(all_best_weights[1][0][0]).transpose()))\n",
    "test_eigen_2 = np.linalg.eig(np.matmul(np.array(all_best_weights[2][0][0]), np.array(all_best_weights[2][0][0]).transpose()))\n",
    "test_eigen_3 = np.linalg.eig(np.matmul(np.array(all_best_weights[3][0][0]), np.array(all_best_weights[3][0][0]).transpose()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape's 10th coliumn of eigenvector\n",
    "\n",
    "eigen_nocomplex_10 = np.reshape(test_eigen_0[1][:, 9], (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional matrix multiplication of eigenvectors\n",
    "rf_AVA_eigen_10 = np.matmul(eigen_nocomplex_10, eigen_nocomplex_10.T )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf_AVA_eigen_10)\n",
    "plt.title(\"Receptive Field of 10th Eigenvector of AVA Cell 0 in Worm 0, Stim 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(eigen_nocomplex_10)\n",
    "plt.title(\"Receptive Field of 10th Eigenvector of AVA Cell 0 in Worm 0, Stim 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tenth eigenvector from each jackknife model\n",
    "jackknife_0_eigen_10 = np.reshape(test_eigen_0[1][:, 9], (-1, 1))\n",
    "jackknife_1_eigen_10 = np.reshape(test_eigen_1[1][:, 9], (-1, 1))\n",
    "jackknife_2_eigen_10 = np.reshape(test_eigen_2[1][:, 9], (-1, 1))\n",
    "jackknife_3_eigen_10 = np.reshape(test_eigen_3[1][:, 9], (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_AVA_eigen_10 = np.matmul(jackknife_0_eigen_10, jackknife_0_eigen_10.T )\n",
    "rf_AVA_eigen_10 = np.matmul(jackknife_1_eigen_10, jackknife_1_eigen_10.T )\n",
    "rf_AVA_eigen_10 = np.matmul(jackknife_2_eigen_10, jackknife_2_eigen_10.T )\n",
    "rf_AVA_eigen_10 = np.matmul(jackknife_3_eigen_10, jackknife_3_eigen_10.T )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_weights = np.concatenate([\n",
    "    jackknife_0_eigen_10,\n",
    "    jackknife_1_eigen_10,\n",
    "    jackknife_2_eigen_10,\n",
    "    jackknife_3_eigen_10\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_AVA = np.average(AVA_weights, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_AVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_weights_df = pd.DataFrame(AVA_weights)\n",
    "AVA_weights_df.columns = ['Jackknife 1', 'Jackknife 2', 'Jackknife 3', 'Jackknife 4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_weights_df['Average'] = mean_AVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_weights_df.plot(figsize=(10, 6))  # Adjust the size as necessary\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Weights Across Different Models')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Weights Value')\n",
    "plt.grid(True)  # Optional: Adds a grid for better readability\n",
    "\n",
    "# Show the legend and plot\n",
    "plt.legend(title='Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = AVA_weights_df[['Jackknife 1', 'Jackknife 2', 'Jackknife 3', 'Jackknife 4']].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = std_dev / np.sqrt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(x=AVA_weights_df.index, y=mean_AVA, yerr=sem, fmt='-o', label='Average with SEM', ecolor='red', capsize=5, linestyle='-', marker='o', color='blue')\n",
    "plt.title('AVA Receptive Field ')\n",
    "plt.xlabel('Time')\n",
    "ticks = AVA_weights_df.index\n",
    "plt.xticks(ticks, labels=ticks[::-1]) \n",
    "plt.ylabel('Stimulus')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
