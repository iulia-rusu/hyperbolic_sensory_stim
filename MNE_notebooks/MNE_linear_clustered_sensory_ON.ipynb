{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_linear_model(D):\n",
    "\n",
    "    input_layer = keras.layers.Input((D,))\n",
    "\n",
    "    linear_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "    output_layer = keras.layers.Activation('sigmoid')(linear_layer)\n",
    "\n",
    "    model = keras.models.Model(input_layer,output_layer)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_linear_model(D):\n",
    "#     # Define the input shape\n",
    "#     input_layer = keras.layers.Input(shape=(D,))\n",
    "\n",
    "#     # Add a linear (Dense) layer with 1 output neuron\n",
    "#     linear_layer = keras.layers.Dense(1)(input_layer)\n",
    "\n",
    "#     # Use sigmoid activation function for binary classification\n",
    "#     output_layer = keras.layers.Activation('sigmoid')(linear_layer)\n",
    "\n",
    "#     # Create the model\n",
    "#     model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "#     # Compile the model with binary crossentropy loss and an optimizer\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10  # Number of features\n",
    "model = make_linear_model(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 10  # Number of features\n",
    "model_ava1 = make_linear_model(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example psuedo data\n",
    "\n",
    "# inputs = np.random.random((1000, D))  # 1000 samples, D features each\n",
    "# labels = np.random.randint(0, 2, (1000, 1))  # 1000 binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual data import\n",
    "stimulus = np.load('/Users/iuliarusu/Documents/Sharpee/ProcAiryData/inpfull_op50_SF.npz')\n",
    "Y_full = np.load('/Users/iuliarusu/Documents/Sharpee/ProcAiryData/Yfull_op50_SF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import AVA data from all cells\n",
    "AVA_0_df = pd.read_csv ('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_0_df.csv')\n",
    "AVA_1_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_1_df.csv') \n",
    "AVA_2_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_2_df.csv')\n",
    "AVA_3_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_3_df.csv') \n",
    "AVA_4_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_4_df.csv') \n",
    "AVA_5_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_5_df.csv') \n",
    "AVA_6_df = pd.read_csv('/Users/iuliarusu/Documents/Sharpee/Clustering/clustered_bacterial_stim/AVA_6_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_0 = np.array(AVA_0_df.iloc[:, 1: -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_concat = np.concatenate([stimulus['arr_0'], stimulus['arr_1'], stimulus['arr_2'], stimulus['arr_3'], stimulus['arr_4'], stimulus['arr_5'], stimulus['arr_6']], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stimulus_concat = np.concatenate([stimulus['arr_0'], stimulus['arr_1'], stimulus['arr_2'], stimulus['arr_3'], stimulus['arr_4'], stimulus['arr_5'], stimulus['arr_6']], axis =1)\n",
    "# Y_full_concat = np.concatenate([Y_full['arr_0'],\n",
    "#                          Y_full['arr_1'],\n",
    "#                          Y_full['arr_2'],\n",
    "#                          Y_full['arr_3'] , Y_full['arr_4'], Y_full['arr_5'], Y_full['arr_6']], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_bins(stimulus, response, bin_size, start_idx, cell_idx, num_bins = 10):\n",
    "#     response_vector = []\n",
    "#     stimulus_vector = []\n",
    "#     stimulus_matrix = ((num_bins, bin_size))\n",
    "\n",
    "#     if start_idx < num_bins * bin_size:\n",
    "#         print(\"Start index is out of bounds.\")\n",
    "#         return None\n",
    "#     start = response[cell_idx,  start_idx: start_idx + 10] \n",
    "#     response_vector.append(start)\n",
    "#     end = start_idx - (bin_size * num_bins)\n",
    "#     print('end', end)\n",
    "#     print(\"resp\", response_vector)\n",
    "#     stimulus_vector.append(stimulus[ 0, end : start_idx ])\n",
    "#     print(\"stim\", stimulus_vector)\n",
    "#     stimulus_vector = np.array(stimulus_vector)\n",
    "#     stimulus_matrix = stimulus_vector.reshape((num_bins, bin_size))\n",
    "#     return stimulus_matrix, np.array(response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins=10, nsamples=10):\n",
    "    response_vector = []\n",
    "    stimulus_vector = []\n",
    "    for _ in range(nsamples):\n",
    "        r = response[cell_idx, start_idx: start_idx + bin_size]\n",
    "        response_vector.append(np.average(r))\n",
    "        print('response', response_vector)\n",
    "\n",
    "        bin_stimuli = []\n",
    "        for i in range(num_bins):\n",
    "           \n",
    "            end_idx = (start_idx ) - (i * bin_size)\n",
    "            print('start_idx', start_idx)\n",
    "            print('end', end_idx)\n",
    "            start_idx_bin = end_idx + bin_size\n",
    "            print('start_idx_bin', start_idx_bin)\n",
    "\n",
    "            # Check if the calculated index is within the bounds\n",
    "            if start_idx_bin < 0:\n",
    "                break\n",
    "\n",
    "            # Append the average of stimulus over the bin\n",
    "            bin_stimuli.append(np.average(stimulus[0, end_idx:start_idx_bin]))\n",
    "            print('stim', stimulus[0, start_idx_bin:end_idx])\n",
    "            print('bin_stimuli', bin_stimuli)\n",
    "\n",
    "        # Collect all averages per sample\n",
    "        stimulus_vector.append(bin_stimuli)\n",
    "        print('stimulus_vector', stimulus_vector)\n",
    "\n",
    "        # Update start index for the next sample\n",
    "        start_idx += bin_size\n",
    "\n",
    "    # Convert list of lists into a 2D NumPy array\n",
    "    stimulus_matrix = np.array(stimulus_vector)  # Transpose to match expected dimensions\n",
    "\n",
    "    return stimulus_matrix, np.array(response_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_0[0, 200: 200 + 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bin_size = 10\n",
    "start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "num_bins = 10\n",
    "nsamples = 100 #each time point gets multiplied by bin size, as you go along, if you start at t= 200, bin size 10, you'll end at time point 200 + 1000(10) is nsamples = 1000\n",
    "\n",
    "stimulus = stimulus_concat.T\n",
    "response = AVA_0\n",
    "cell_idx = 0 #cell in response\n",
    "\n",
    "data, label = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over each cell in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over each cell index in the DataFrame\n",
    "\n",
    "for cell_idx in range(response.shape[0]//2):\n",
    "    bin_size = 5\n",
    "    start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "    num_bins = 10\n",
    "    nsamples = 100 #amount of times you're moving over the data\n",
    "\n",
    "    stimulus = stimulus_concat.T\n",
    "    response = AVA_1\n",
    "    cell_idx = 0 #cell in response\n",
    "\n",
    "    data, label = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVA_1 = np.array(AVA_1_df.iloc[:, 1: -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_size = 10\n",
    "start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "num_bins = 10\n",
    "nsamples = 100 #each time point gets multiplied by bin size, as you go along, if you start at t= 200, bin size 10, you'll end at time point 200 + 1000(10) is nsamples = 1000\n",
    "\n",
    "stimulus = stimulus_concat.T\n",
    "response = AVA_1\n",
    "cell_idx = 0 #cell in response\n",
    "\n",
    "data, label = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize containers for data and labels\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "bin_size = 10\n",
    "start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "num_bins = 10\n",
    "nsamples = 100 #amount of times you're moving over the data\n",
    "\n",
    "stimulus = stimulus_concat.T\n",
    "response = AVA_1\n",
    "cell_idx = 0 #cell in response\n",
    "# Calculate data and labels for each cell or half the cells\n",
    "num_cells = response.shape[0]//2  # or response.shape[0] // 2 for half of the cells\n",
    "for cell_idx in range(num_cells):\n",
    "    data, label = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)\n",
    "    all_data.append(data)\n",
    "    all_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_array = np.concatenate(all_data, axis=0)\n",
    "\n",
    "# Convert list of 1D arrays to a single 2D array (if all_labels consists of 1D arrays)\n",
    "all_labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data\n",
    "labels = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = all_data_array  # 100 samples, D features each\n",
    "labels = all_labels_array  # 100 labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "model.fit(inputs, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ava1.fit(inputs, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size = 10\n",
    "start_idx = 200  # Starting index for the stimulus and response extraction\n",
    "num_bins = 10\n",
    "nsamples = 50\n",
    "\n",
    "stimulus = stimulus_concat.T\n",
    "response = AVA_0\n",
    "cell_idx =  9 #cell in response\n",
    "\n",
    "data_test, label_test = get_bins_avg(stimulus, response, bin_size, start_idx, cell_idx, num_bins, nsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test  # your test stimuli\n",
    "\n",
    "# Predict the response probabilities\n",
    "predicted_probabilities = model.predict(X_test)\n",
    "\n",
    "# If you need binary responses (firing or not firing), you can threshold these probabilities:\n",
    "predicted_responses = (predicted_probabilities >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights\n",
    "\n",
    "model.weights[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ava1.weights\n",
    "\n",
    "model_ava1.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(model_ava1.weights[0])\n",
    "plt.title(\"Linear MNE: AVA Receptive Field for single AVA cell in Worm 0 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(model.weights[0])\n",
    "plt.title(\"Linear MNE: AVA Receptive Field for AVA all cell in Worm 0 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(model.weights[0])\n",
    "plt.title(\"Linear MNE: AVA Receptive Field for AVA cell in Worm 0 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bulk processing of all cells in a "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
