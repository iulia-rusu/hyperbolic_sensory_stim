{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb521f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method developed by Anoop Praturu: https://www.biorxiv.org/content/10.1101/2022.10.12.511940v1\n",
    "Code from Anoop Praturu on Oct 2021\n",
    "Move from pystan to cmdstanpy based on suggestions by Milo Julis\n",
    "Edited by Mingchen Yao on May 26 2023\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import diptest  \n",
    "import matplotlib.pyplot as plt\n",
    "import cmdstanpy as stan\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from matplotlib import rcParams\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if there is anything wrong with comstan: re-install it. Otherwise don't run this cell\n",
    "# from cmdstanpy import install_cmdstan\n",
    "# install_cmdstan(overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c280a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f95b0f",
   "metadata": {},
   "source": [
    "# Functions for Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16c0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns hyperbolic distance between vectors in poincare ball\n",
    "def poincare_dist(v1, v2):\n",
    "    sq = np.sum(np.square(v1-v2))\n",
    "    r1 = np.sum(np.square(v1))\n",
    "    r2 = np.sum(np.square(v2))\n",
    "    inv = 2.0*sq/((1.0-r1)*(1.0-r2))\n",
    "    return np.arccosh(1.0 + inv)\n",
    "\n",
    "#return NxN symmetric distance matrix from poincare coordinates\n",
    "def get_dmat(p_coords):\n",
    "    N = p_coords.shape[0]\n",
    "    dists = np.zeros((N, N))\n",
    "    \n",
    "    for i in np.arange(N):\n",
    "        for j in np.arange(i+1, N):\n",
    "            dists[i][j] = poincare_dist(p_coords[i], p_coords[j])\n",
    "            dists[j][i] = dists[i][j]\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f942b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 100 data points uniformly distributed in 5 dimensional hyperbolic space of radius R=4\n",
    "dim=5; R=4.0;\n",
    "n=100\n",
    "dirs = stats.norm.rvs(size=(n, dim))\n",
    "dirs = (dirs.T/np.sqrt(np.sum(np.square(dirs), axis=1))).T\n",
    "U = stats.uniform.rvs(size=n)\n",
    "rs_p = np.tanh(np.log((1-np.exp(-R))/np.exp(-R)*(U) + 1.0)/2.0)\n",
    "p_coords = rs_p.reshape(-1,1)*dirs\n",
    "\n",
    "#add noise to the computed distance matrix to simulate a more realistic dataset\n",
    "mat_dim = get_dmat(p_coords) + 0.05*R*stats.norm.rvs(size=(n,n))\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(i+1, n):\n",
    "        mat_dim[j][i] = mat_dim[i][j]\n",
    "mat_dim = 2.0*mat_dim/np.max(mat_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7bb38",
   "metadata": {},
   "source": [
    "# Code for fitting Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7b4752",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/iuliarusu/Documents/Sharpee/HMDS-example/model/'\n",
    "ltz_m = stan.CmdStanModel(stan_file=path+'lorentz.stan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61d6d2",
   "metadata": {},
   "source": [
    "# whole worm no cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b73b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "bacteria = np.load('/Users/iuliarusu/Documents/Sharpee/ProcAiryData/Yfull_op50_SF.npz')\n",
    "bacteria_arr_0= bacteria['arr_1']\n",
    "bacteria_0_df = pd.DataFrame(bacteria_arr_0)\n",
    "corr_matrix = bacteria_0_df.corr()\n",
    "distance_matrix = 1 - corr_matrix\n",
    "distance_matrix_squaredp = (1 - corr_matrix**2) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac053860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 135)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_matrix_squaredp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db4cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:20:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:27:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "#dictionary to specify input to simulation\n",
    "\n",
    "# dat={'N':100, 'D':5, 'deltaij':mat_dim}\n",
    "dat = {'N': 135 , 'D': 3 , 'deltaij':distance_matrix_squaredp}\n",
    "#run optimizer\n",
    "model = ltz_m.optimize(data=dat, iter=250000, algorithm='LBFGS', tol_rel_grad=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a880a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build result \n",
    "hyp_emb = {'euc':model.euc, 'sig':model.sig, 'lambda':model.stan_variable('lambda')}\n",
    "\n",
    "# # and save\n",
    "# fdname = './emb5d.pickle'\n",
    "# with open(fdname,'wb') as file:\n",
    "#     pickle.dump(hyp_emb, file,  protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load existing results\n",
    "# fdname = './emb5d.pickle'\n",
    "# with open(fdname, 'rb') as file:\n",
    "#     hyp_emb = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a4cf9",
   "metadata": {},
   "source": [
    "## Some utility functions for post-processing the simulation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f033e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_lor(t1, t2, E1, E2):\n",
    "    return np.arccosh(t1*t2 - np.dot(E1, E2))\n",
    "\n",
    "#returns embedding distance matrix from optimization fit\n",
    "def get_embed_dmat(fit):\n",
    "    N = fit['euc'].shape[0]\n",
    "    fit_ts = np.sqrt(1.0 + np.sum(np.square(fit['euc']), axis=1))\n",
    "\n",
    "    fit_mat = np.zeros((N, N))\n",
    "\n",
    "    for i in np.arange(N):\n",
    "        for j in np.arange(i+1,N):\n",
    "            fit_mat[i][j] = d_lor(fit_ts[i], fit_ts[j], fit['euc'][i], fit['euc'][j])\n",
    "            fit_mat[j][i] = fit_mat[i][j]\n",
    "            \n",
    "    return fit_mat\n",
    "\n",
    "#return poincare coordinates\n",
    "def get_poin(fit):\n",
    "    ts = np.sqrt(1.0 + np.sum(np.square(fit['euc']), axis=1))\n",
    "    return (fit['euc'].T / (ts + 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sim(fit):\n",
    "    fit['emb_mat'] = get_embed_dmat(fit)/fit['lambda']\n",
    "    fit['pcoords'] = get_poin(fit)\n",
    "    fit['radii'] = 2.0*np.arctanh(np.sqrt(np.sum(np.square(fit['pcoords']), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this function after running the optimizer to process the output data into more usable forms\n",
    "process_sim(hyp_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curvature (or radius)\n",
    "hyp_emb['lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa441edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poincare embedding coordinates\n",
    "hyp_emb['pcoords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1_unclustered = hyp_emb['pcoords']\n",
    "%store w_1_unclustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emebdding uncertainties\n",
    "hyp_emb.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4a0f2",
   "metadata": {},
   "source": [
    "# Shepard Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68aec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b924846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color brewer paisley hex color references\n",
    "#8dd3c7\n",
    "#ffffb3\n",
    "#bebada\n",
    "#fb8072\n",
    "#80b1d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(3.7 * 2, 3.7))\n",
    "\n",
    "ax[0].scatter(distance_matrix_squaredp.values[np.triu_indices(28, k=1)], hyp_emb['emb_mat'][np.triu_indices(28, k=1)], c='#8dd3c7', edgecolor='black', alpha=0.7) #cornflowerblue, lightcoral\n",
    "ax[0].plot(np.arange(3), np.arange(3), c='black', linewidth=5, alpha=0.5)\n",
    "r2 = r2_score(distance_matrix_squaredp.values[np.triu_indices(28, k=1)], hyp_emb['emb_mat'][np.triu_indices(28, k=1)])\n",
    "\n",
    "ax[0].set_xlabel('Original Distances', fontsize=20)\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=20)\n",
    "ax[0].set_ylabel('Embedding Distances / $\\lambda$', fontsize=20)\n",
    "# ax[0].text(0.1, 2.5, f'R**2 = {r2:.2f}', fontsize=20)\n",
    "ax[0].text(0.1, 2.5, f'$R^2 = {r2:.2f}$', fontsize=20, verticalalignment='top')\n",
    "\n",
    "ax[1].hist(hyp_emb['sig'], color ='#bebada', edgecolor='black') #cornflowerblue, lightcoral\n",
    "ax[1].set_xlabel('Embedding Uncertainties', fontsize=20)\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "plt.savefig('/Users/iuliarusu/Documents/Sharpee/final_images/figure2/singlew_embedding_w1.svg', format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea16b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperbolic_df= pd.DataFrame(hyp_emb['pcoords'], columns=['x', 'y', 'z'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4caf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell type label column\n",
    "column = ['ON'] * (ON_0.shape[0]) + ['OFF'] * (OFF_0.shape[0]) + ['AVA'] * (AVA_0.shape[0]) + ['RME'] * (RME_0.shape[0]) + ['SMDV'] * (SMDV_0.shape[0]) + ['SMDD'] * (SMDD_0.shape[0])\n",
    "cell_type = np.array(column)\n",
    "hyperbolic_df['cluster labels'] = cell_type.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eddd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8dd3c7\n",
    "#ffffb3\n",
    "#bebada\n",
    "#fb8072\n",
    "#80b1d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13337882",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperbolic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "# fig = px.scatter_3d(data_frame = hyperbolic_df, x= 'x', y = 'y', z= 'z', title='AVA and RME: Stimulus 0', color = 'cluster labels') #cornflowerblue, lightcoral\n",
    "\n",
    "fig = px.scatter_3d(data_frame = hyperbolic_df, x= 'x', y = 'y', z= 'z', title='ON and OFF Neurons: Bacterial Stimulus No. 0' ) #cornflowerblue, lightcoral\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(ticktext=[-1, -0.5, 0, 0.5, 1]),\n",
    "        yaxis=dict(ticktext=[-1, -0.5, 0, 0.5, 1]),\n",
    "        zaxis=dict(ticktext=[-1, -0.5, 0, 0.5, 1]),\n",
    "        )\n",
    ")\n",
    "fig.update_traces(marker=dict(color='#80b1d3', size=8, opacity = 0.8))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    data_frame=hyperbolic_df, \n",
    "    x='x', \n",
    "    y='y', \n",
    "    z='z', \n",
    "     \n",
    "    # text='cluster labels',  # assuming 'labels' column contains the point labels\n",
    "    # title='ON and OFF Neurons',\n",
    "    labels={'x': 'X', 'y': 'Y', 'z': 'Z'},\n",
    "    \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            tickvals=[-1, -0.5, 0, 0.5, 1],\n",
    "            ticktext=['-1', '-0.5', '0', '0.5', '1'],\n",
    "            title=dict(text='X', font=dict(size=20)),\n",
    "            tickfont=dict(size=15)\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            tickvals=[-1, -0.5, 0, 0.5, 1],\n",
    "            ticktext=['-1', '-0.5', '0', '0.5', '1'],\n",
    "            title=dict(text='Y ', font=dict(size=20)),\n",
    "            tickfont=dict(size=15)\n",
    "            \n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            tickvals=[-1, -0.5, 0, 0.5, 1],\n",
    "            ticktext=['-1', '-0.5', '0', '0.5', '1'],\n",
    "            title=dict(text='Z ', font=dict(size=20)),\n",
    "            tickfont=dict(size=15)\n",
    "            \n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(text='Cluster Labels', font=dict(size=12)),\n",
    "        font=dict(size=10)\n",
    "    # ),\n",
    "    # title=dict(\n",
    "    #     text='ON and OFF Neurons',\n",
    "    #     font=dict(size=15)\n",
    "    ),\n",
    "    margin=dict(l=20, r=20, b=90, t=40),\n",
    "    autosize=True,\n",
    "    width=700,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Customize marker size and opacity for better visualization\n",
    "fig.update_traces(marker=dict(size=10, opacity=0.8, color='#8dd3c7' ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6080734",
   "metadata": {},
   "source": [
    "# Fitting For Dimension\n",
    "\n",
    "Suppose we did not know a-priori that the data was 5D? This is usually the case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e919b",
   "metadata": {},
   "source": [
    "## Fit the model across a range of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffeb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fits = []\n",
    "for d in np.arange(2,15):\n",
    "    dat={'N':135, 'D':d, 'deltaij':distance_matrix_squaredp}\n",
    "    #run optimizer\n",
    "    model = ltz_m.optimize(data=dat, iter=250000, algorithm='LBFGS', tol_rel_grad=1e2)\n",
    "    all_fits.append({'euc':model.euc, 'sig':model.sig, 'lambda':model.stan_variable('lambda'), 't':model.time})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddd178",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.stan_variable('lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f93260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda extracted for specific dimension\n",
    "all_fits[4]['lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e53bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access the correct iteration \n",
    "iteration = all_fits[6]['t']\n",
    "\n",
    "\n",
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f3521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate radii based on time parameter\n",
    "radii = np.arccosh(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1_radii = radii\n",
    "%store w_1_radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of radii\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "\n",
    "ax.scatter(np.arange(2,15), all_BIC, c = '#8dd3c7', edgecolor = 'black', s = 200) #cornflowerblue, lightcoral\n",
    "ax.set_xlabel('Dimension', fontsize=35)\n",
    "ax.tick_params(axis='both', which='major', labelsize=25)\n",
    "ax.set_xticks(np.arange(2, 15, 2))\n",
    "ax.set_ylabel('BIC', fontsize=35)\n",
    "\n",
    "plt.savefig('/Users/iuliarusu/Documents/Sharpee/final_images/figure2/singlew_BIC_w1.svg', format='svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c766bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIP analysis of radii\n",
    "dip, pval = diptest.diptest(radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac64e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dip, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b674d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fits[0]['sig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return negative log likelihood of fit\n",
    "def MDS_lkl(fit, dmat):\n",
    "    lkl = 0;\n",
    "    N = fit['sig'].shape[0]\n",
    "    \n",
    "    sigs = fit['sig']\n",
    "    lam = fit['lambda']\n",
    "    emb_mat = get_embed_dmat(fit)\n",
    "    \n",
    "    for i in np.arange(N):\n",
    "        for j in np.arange(i+1, N):\n",
    "            seff = sigs[i]**2 + sigs[j]**2\n",
    "            lkl += ((dmat[i][j] - emb_mat[i][j]/lam)**2 / (2.0*seff)) + 0.5*np.log(seff*2.0*np.pi)\n",
    "    return lkl\n",
    "\n",
    "#input: optimization fit and distance matrix\n",
    "def BIC(fit, dmat):\n",
    "    N,D = fit['euc'].shape\n",
    "    n = 0.5*N*(N-1)\n",
    "    k = N*D + N + 1.0 - 0.5*D*(D-1)\n",
    "    \n",
    "    return k*np.log(n) + 2.0*MDS_lkl(fit, dmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ccab40",
   "metadata": {},
   "source": [
    "## Bayesian information criteria\n",
    "\n",
    "There is a lot of formal Bayesian Theory behind this (see chapter 2 here https://urldefense.proofpoint.com/v2/url?u=https-3A__www.inference.org.uk_mackay_thesis.pdf&d=DwIGAg&c=-35OiAkTchMrZOngvJPOeA&r=B8GeUuyHfxQP8MseZuhipQ&m=KVww4gh9-XOtp1LqNUc0K-PGXOX3bm2QsokPFlBG9Vs&s=UBtNEdIXatq_zFpG53nmPCLbCnlgIgWigHYhEnBRYyo&e= ), but essentially we are trying to find the minimal number of parameters to describe a dataset. If the data is 5D, we don't want to use 7 parameters to describe it. The BIC is like a cost function that rewards a model that has a better fit to the likelihood function, but penalizes models that increase the number of their parameters. The model which minimizes this function will thus have the ideal trade-off of being able to model the data well without introducing too many parameters and overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3688551",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_BIC = [BIC(fit, distance_matrix_squaredp) for fit in all_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1160cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae8d10",
   "metadata": {},
   "source": [
    "As you can see the BIC is minimized at the true dimension of 5. Any more parameters would have been redundant, any less would not have properly fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3160255",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7.5,7.5))\n",
    "\n",
    "ax.scatter(np.arange(2,15), all_BIC, c = '#8dd3c7', edgecolor = 'black', s = 200) #cornflowerblue, lightcoral\n",
    "ax.set_xlabel('Dimension', fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "ax.set_ylabel('BIC', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce171280",
   "metadata": {},
   "source": [
    "# Re-Running the optimizer\n",
    "Lets start by generating some 2D data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6d256",
   "metadata": {},
   "source": [
    "What is the purpose of re-running?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 100 data points uniformly distributed in 5 dimensional hyperbolic space of radius R=4\n",
    "dim=2; R=4.0;\n",
    "n=100\n",
    "dirs = stats.norm.rvs(size=(n, dim))\n",
    "dirs = (dirs.T/np.sqrt(np.sum(np.square(dirs), axis=1))).T\n",
    "U = stats.uniform.rvs(size=n)\n",
    "rs_p = np.tanh(np.log((1-np.exp(-R))/np.exp(-R)*(U) + 1.0)/2.0)\n",
    "p_coords = rs_p.reshape(-1,1)*dirs\n",
    "\n",
    "#add noise to the computed distance matrix to simulate a more realistic dataset\n",
    "mat_2D = get_dmat(p_coords) + 0.05*R*stats.norm.rvs(size=(n,n))\n",
    "for i in np.arange(n):\n",
    "    for j in np.arange(i+1, n):\n",
    "        mat_2D[j][i] = mat_2D[i][j]\n",
    "mat_2D = 2.0*mat_2D/np.max(mat_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f65f1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to specify input to simulation\n",
    "dat={'N':76, 'D':6, 'deltaij':distance_matrix_squaredp}\n",
    "#run optimizer\n",
    "model2D = ltz_m.optimize(data=dat, iter=250000, algorithm='LBFGS', tol_rel_grad=1e2)\n",
    "hyp_emb2D = {'euc':model2D.euc, 'sig':model2D.sig, 'lambda':model2D.stan_variable('lambda')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_sim(hyp_emb2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed16b6",
   "metadata": {},
   "source": [
    "#### Most pts are well fit, but a few are poorly fit (the ones with high sigma) which adds a lot of scatter to the shepard diagram\n",
    "#### The optimizer got caught in a false minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bddb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can't find 'emb_mat' parameter \n",
    "hyp_emb2D.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8c2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,7.5))\n",
    "\n",
    "ax[0].scatter(distance_matrix_squaredp[np.triu_indices(76, k=1)], hyp_emb2D['sig'][np.triu_indices(76, k=1)])\n",
    "ax[0].plot(np.arange(3), np.arange(3), c='black', linewidth=5, alpha=0.5)\n",
    "\n",
    "ax[0].set_xlabel('Original Distances', fontsize=20)\n",
    "ax[0].set_ylabel('Embedding Distances / $\\lambda$', fontsize=20)\n",
    "\n",
    "ax[1].hist(hyp_emb2D['sig'])\n",
    "ax[1].set_xlabel('Embedding Uncertainties', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edc498",
   "metadata": {},
   "source": [
    "### Strategy: randomize the positions of the poorly fit points, and then return the coordinates as the initial conditions to continue optimizing. This bumps the simulation out of the false minimium without destroying all of the work its already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47006a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out which pts have high uncertainty, and randomize their coordinates without touching the rest of the points\n",
    "N_refit = np.where(hyp_emb2D['sig'] > 0.3)[0].shape[0]\n",
    "hyp_emb2D['euc'][np.where(hyp_emb2D['sig'] > 0.3)] = stats.norm.rvs(size=(N_refit,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-reun the optimizer, but this time sepcify the initial condition by passing the previous simulation dictionary\n",
    "dat={'N':100, 'D':2, 'deltaij':mat_2D}\n",
    "model2D = ltz_m.optimize(data=dat, iter=250000, algorithm='LBFGS', tol_rel_grad=1e2,inits = hyp_emb2D)\n",
    "hyp_emb2D = {'euc':model2D.euc, 'sig':model2D.sig, 'lambda':model2D.stan_variable('lambda')}\n",
    "# tst_2D = ltz_m.optimizing(data=dat, iter=250000, tol_rel_grad=1e2, init=tst_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc911c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_sim(hyp_emb2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28b534e",
   "metadata": {},
   "source": [
    "### We see that the fit is significantly better, although there are still a few poorly fit points. We could keep iterating the above process until all points are well fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fa17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15,7.5))\n",
    "\n",
    "ax[0].scatter(mat_2D[np.triu_indices(100, k=1)], hyp_emb2D['emb_mat'][np.triu_indices(100, k=1)])\n",
    "ax[0].plot(np.arange(3), np.arange(3), c='black', linewidth=5, alpha=0.5)\n",
    "\n",
    "ax[0].set_xlabel('Original Distances', fontsize=20)\n",
    "ax[0].set_ylabel('Embedding Distances / $\\lambda$', fontsize=20)\n",
    "\n",
    "ax[1].hist(hyp_emb2D['sig'])\n",
    "ax[1].set_xlabel('Embedding Uncertainties', fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
